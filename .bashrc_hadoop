# Hadoop commands

alias hstart='$HADOOP_HOME/sbin/hadoop-daemon.sh start namenode;$HADOOP_HOME/sbin/start-dfs.sh;$HADOOP_HOME/sbin/start-yarn.sh;$HADOOP_HOME/sbin/yarn-daemon.sh start nodemanager;$HADOOP_HOME/sbin/hadoop-daemon.sh start datanode'
alias hstop='$HADOOP_HOME/sbin/stop-yarn.sh;$HADOOP_HOME/sbin/stop-dfs.sh;$HADOOP_HOME/sbin/hadoop-daemon.sh stop namenode;$HADOOP_HOME/sbin/hadoop-daemon.sh stop datanode;$HADOOP_HOME/sbin/yarn-daemon.sh stop nodemanager'

alias spark_start='$SPARK_HOME/sbin/start-all.sh'
alias spark_stop='$SPARK_HOME/sbin/stop-all.sh'

alias hive_metastore_start='nohup $HIVE_HOME/bin/hive --service metastore > $HIVE_HOME/logs/hivemetastore.log 2>&1 &'
alias hiveserver2='nohup $HIVE_HOME/bin/hiveserver2 > $HIVE_HOME/logs/hiveserver2.log 2>&1 &'
alias beeline='$HIVE_HOME/bin/beeline -u jdbc:hive2://localhost:10000/default -n hive -p hive'
